{"pageProps":{"code":[{"linkUrl":"/code/patchnetvlad_code","mediaPosition":"center","mediaUrls":["/_next/static/images/patch_netvlad_method_diagram-a9187148aad4ff631ce8f55f695459ec.png.webp","/_next/static/images/patch_netvlad_method_diagram-26dab363c927eaf0c0020decf330646e.png"],"primaryText":"Patch-NetVLAD","secondaryText":"QVPR/Patch-NetVLAD","secondaryTransform":"lowercase"},{"linkUrl":"/code/seqnet_code","mediaPosition":"center","mediaUrls":["/_next/static/images/seqnet-cfc1aecd3cd2b268af41400a4fb86e6a.jpg.webp","/_next/static/images/seqnet-69de71978f2b7f0ffbcefcbb976010d3.jpg"],"primaryText":"SeqNet","secondaryText":"oravus/seqNet","secondaryTransform":"lowercase"},{"linkUrl":"/code/vprbench","mediaPosition":"center","mediaUrls":["/_next/static/images/VPRBench-a4fbe919a2ac5fc851261353f3fbdd9a.jpg.webp","/_next/static/images/VPRBench-5db45a25afa26692b0958cbf579b9a77.jpg"],"primaryText":"VPR-Bench","secondaryText":"MubarizZaffar/VPR-Bench","secondaryTransform":"lowercase"},{"linkUrl":"/code/delta_descriptors_code","mediaPosition":"center","mediaUrls":["/_next/static/images/ral-iros-2020-delta-descriptors-schematic-b5f57732c327f2f8546715b5dc3643af.png.webp","/_next/static/images/ral-iros-2020-delta-descriptors-schematic-95f5d1a50f3d92aa3344d9782ac13c32.png"],"primaryText":"Delta Descriptors","secondaryText":"oravus/DeltaDescriptors","secondaryTransform":"lowercase"},{"linkUrl":"/code/event_vpr_code","mediaPosition":"center","mediaUrls":["/_next/static/images/dataset-77ee27292f9a639c3024670f2a9939e2.png.webp","/_next/static/images/dataset-179d4dc0b9d40cbdc11117c78f1d45de.png"],"primaryText":"Visual Place Recognition using Event Cameras","secondaryText":"Tobias-Fischer/ensemble-event-vpr","secondaryTransform":"lowercase"},{"linkUrl":"/code/lost_code","mediaPosition":"center","mediaUrls":["/_next/static/images/day-night-keypoint-correspondence-place-recognition-38203057bf036a1e9271b0a7647119fa.jpg.webp","/_next/static/images/day-night-keypoint-correspondence-place-recognition-bed6f778b7ec1ce4edaa346e24fb33bf.jpg"],"primaryText":"LoST-X","secondaryText":"oravus/lostX","secondaryTransform":"lowercase"},{"linkUrl":"/code/openseqslam2_code","mediaPosition":"center","mediaUrls":["/_next/static/images/openseqslam2-c5079d59d4cff5bd652acb1652d047f6.png.webp","/_next/static/images/openseqslam2-f3755fc8e61c0d81c8f0b0f42c5e08ae.png"],"primaryText":"OpenSeqSLAM2","secondaryText":"qcr/openseqslam2","secondaryTransform":"lowercase"},{"linkUrl":"/code/seq2single_code","mediaPosition":"center","mediaUrls":["/_next/static/images/illustration-73bec1a3cac56819cdbea1268b711fa4.png.webp","/_next/static/images/illustration-1e185173132d7d8138449660ac905c04.png"],"primaryText":"seq2single","secondaryText":"oravus/seq2single","secondaryTransform":"lowercase"},{"linkUrl":"/code/teach_repeat","mediaPosition":"center","mediaUrls":["/_next/static/images/outdoor-run-c6d0f9054f19ca3ca4a9c32ae5089b50.webm","/_next/static/images/outdoor-run-c6d0f9054f19ca3ca4a9c32ae5089b50.mp4","/_next/static/images/outdoor-run-c6d0f9054f19ca3ca4a9c32ae5089b50.webp","/_next/static/images/outdoor-run-c6d0f9054f19ca3ca4a9c32ae5089b50.jpg"],"primaryText":"Visual Teach and Repeat","secondaryText":"QVPR/teach-repeat","secondaryTransform":"lowercase"},{"linkUrl":"/code/heaputil_code","mediaPosition":"center","mediaUrls":["/_next/static/images/overview-8c193585e23714439d55f0227d88f923.jpg.webp","/_next/static/images/overview-fc609d6102a3c08cb20b14382e57ee50.jpg"],"primaryText":"HEAPUtil","secondaryText":"Nik-V9/HEAPUtil","secondaryTransform":"lowercase"},{"linkUrl":"/code/topometric_localization","mediaPosition":"center","mediaUrls":["/qcr_logo_light_filled.svg"],"primaryText":"Place-aware Topometric Localization","secondaryText":"mingu6/TopometricLoc","secondaryTransform":"lowercase"},{"linkUrl":"/code/vpr_snn","mediaPosition":"center","mediaUrls":["/_next/static/images/Ens_of_modularSNNs-b59ff02969917c2eb544fd14a2014936.png.webp","/_next/static/images/Ens_of_modularSNNs-2e12118a078b9b819e6e9169d4994b74.png"],"primaryText":"Spiking Neural Networks for Visual Place Recognition","secondaryText":"QVPR/VPRSNN","secondaryTransform":"lowercase"}],"collectionData":{"content":"<p>This collection features code related to Visual Place Recognition (VPR) research, which is concerned with the fundamental problem of how a robot or autonomous vehicle uses perception to create maps and calculates and tracks its location in the world. Research questions include addressing how:</p>\n<ul>\n<li>the appearance of a place changes in relation as a function of time, season, weather, viewpoint and environment type</li>\n<li>understanding context and semantics can enhance performance</li>\n<li>lifelong reliability can be achieved as the world continually changes</li>\n<li>the relationship to neurological structures and behavioural mechanisms are used in animal and human navigation; and how new perception technologies can be applied to this problem.</li>\n</ul>\n","name":"Visual Place Recognition","type":"collection","url":"https://github.com/qvpr","id":"vpr_overview","code":["patchnetvlad_code","seqnet_code","vprbench","delta_descriptors_code","event_vpr_code","lost_code","openseqslam2_code","seq2single_code","teach_repeat","heaputil_code","topometric_localization","vpr_snn"],"datasets":["brisbane_event_vpr_dataset","vprbench"],"feature":4,"src":"/content/visual_place_recognition/project.md","image_position":"center","_code":[],"_datasets":[],"image":"./assets/patch_netvlad_method_diagram.png","_images":["/_next/static/images/patch_netvlad_method_diagram-a9187148aad4ff631ce8f55f695459ec.png.webp","/_next/static/images/patch_netvlad_method_diagram-26dab363c927eaf0c0020decf330646e.png"]},"datasets":[{"linkUrl":"/dataset/brisbane_event_vpr_dataset","mediaFit":"contain","mediaPosition":"center","mediaUrls":["/_next/static/images/dataset-77ee27292f9a639c3024670f2a9939e2.png.webp","/_next/static/images/dataset-179d4dc0b9d40cbdc11117c78f1d45de.png"],"primaryText":"Brisbane-Event-VPR","secondaryText":"80GB","secondaryTransform":"capitalize"},{"linkUrl":"/dataset/vprbench","mediaFit":"contain","mediaPosition":"center","mediaUrls":["/_next/static/images/VPRBench-a4fbe919a2ac5fc851261353f3fbdd9a.jpg.webp","/_next/static/images/VPRBench-5db45a25afa26692b0958cbf579b9a77.jpg"],"primaryText":"VPR-Bench","secondaryText":"20GB","secondaryTransform":"capitalize"}]},"__N_SSG":true}