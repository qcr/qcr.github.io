{"pageProps":{"codeData":{"content":"<h1>RT-GENE &amp; RT-BENE: Real-Time Eye Gaze and Blink Estimation in Natural Environments</h1>\n<p><a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\"><picture><img alt=\"License: CC BY-NC-SA 4.0\" src=\"https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg?style=flat-square\"></picture></a>\n<a href=\"https://github.com/Tobias-Fischer/rt_gene/stargazers\"><picture><img alt=\"stars\" src=\"https://img.shields.io/github/stars/Tobias-Fischer/rt_gene.svg?style=flat-square\"></picture></a>\n<a href=\"https://github.com/Tobias-Fischer/rt_gene/issues\"><picture><img alt=\"GitHub issues\" src=\"https://img.shields.io/github/issues/Tobias-Fischer/rt_gene.svg?style=flat-square\"></picture></a>\n<a href=\"./README.md\"><picture><img alt=\"GitHub repo size\" src=\"https://img.shields.io/github/repo-size/Tobias-Fischer/rt_gene.svg?style=flat-square\"></picture></a></p>\n<p><a href=\"https://paperswithcode.com/sota/gaze-estimation-on-mpii-gaze?p=rt-gene-real-time-eye-gaze-estimation-in?style=square\"><picture><img alt=\"PWC\" src=\"https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/rt-gene-real-time-eye-gaze-estimation-in/gaze-estimation-on-mpii-gaze&amp;style=flat-square\"></picture></a>\n<a href=\"https://paperswithcode.com/sota/gaze-estimation-on-rt-gene?p=rt-gene-real-time-eye-gaze-estimation-in\"><picture><img alt=\"PWC\" src=\"https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/rt-gene-real-time-eye-gaze-estimation-in/gaze-estimation-on-rt-gene&amp;style=flat-square\"></picture></a>\n<a href=\"https://paperswithcode.com/sota/gaze-estimation-on-ut-multi-view?p=rt-gene-real-time-eye-gaze-estimation-in\"><picture><img alt=\"PWC\" src=\"https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/rt-gene-real-time-eye-gaze-estimation-in/gaze-estimation-on-ut-multi-view&amp;style=flat-square\"></picture></a></p>\n<p><a href=\"https://paperswithcode.com/sota/blink-estimation-on-eyeblink8?p=rt-bene-a-dataset-and-baselines-for-real-time\"><picture><img alt=\"PWC\" src=\"https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/rt-bene-a-dataset-and-baselines-for-real-time/blink-estimation-on-eyeblink8&amp;style=flat-square\"></picture></a>\n<a href=\"https://paperswithcode.com/sota/blink-estimation-on-researcher-s-night?p=rt-bene-a-dataset-and-baselines-for-real-time\"><picture><img alt=\"PWC\" src=\"https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/rt-bene-a-dataset-and-baselines-for-real-time/blink-estimation-on-researcher-s-night&amp;style=flat-square\"></picture></a>\n<a href=\"https://paperswithcode.com/sota/blink-estimation-on-rt-bene?p=rt-bene-a-dataset-and-baselines-for-real-time\"><picture><img alt=\"PWC\" src=\"https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/rt-bene-a-dataset-and-baselines-for-real-time/blink-estimation-on-rt-bene&amp;style=flat-square\"></picture></a></p>\n<p>This repository contains code and dataset references for two papers: <a href=\"http://openaccess.thecvf.com/content_ECCV_2018/html/Tobias_Fischer_RT-GENE_Real-Time_Eye_ECCV_2018_paper.html\">RT-GENE (Gaze Estimation; ECCV2018)</a> and <a href=\"http://openaccess.thecvf.com/content_ICCVW_2019/html/GAZE/Cortacero_RT-BENE_A_Dataset_and_Baselines_for_Real-Time_Blink_Estimation_in_ICCVW_2019_paper.html\">RT-BENE (Blink Estimation; ICCV2019 Workshops)</a>.</p>\n<h2>RT-GENE (Gaze Estimation)</h2>\n<h3>License + Attribution</h3>\n<p>The RT-GENE code is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">CC BY-NC-SA 4.0</a>. Commercial usage is not permitted. If you use this dataset or the code in a scientific publication, please cite the following <a href=\"http://openaccess.thecvf.com/content_ECCV_2018/html/Tobias_Fischer_RT-GENE_Real-Time_Eye_ECCV_2018_paper.html\">paper</a>:</p>\n<p><picture><img alt=\"Paper abstract\" src=\"https:/github.com/Tobias-Fischer/rt_gene/raw/HEAD/assets/paper_abstract.jpg\"></picture></p>\n<pre><code>@inproceedings{FischerECCV2018,\nauthor = {Tobias Fischer and Hyung Jin Chang and Yiannis Demiris},\ntitle = {{RT-GENE: Real-Time Eye Gaze Estimation in Natural Environments}},\nbooktitle = {European Conference on Computer Vision},\nyear = {2018},\nmonth = {September},\npages = {339--357}\n}\n</code></pre>\n<p>This work was supported in part by the Samsung Global Research Outreach program, and in part by the EU Horizon 2020 Project PAL (643783-RIA).</p>\n<h3>Overview + Accompanying Dataset</h3>\n<p>The code is split into four parts, each having its own README contained. There is also an accompanying <a href=\"https://zenodo.org/record/2529036\">dataset</a> <a href=\"https://goo.gl/tfUaDm\">(alternative link)</a> to the code. For more information, other datasets and more open-source software please visit the Personal Robotic Lab's website: <a href=\"https://www.imperial.ac.uk/personal-robotics/software/\">https://www.imperial.ac.uk/personal-robotics/software/</a>.</p>\n<h4>RT-GENE ROS package</h4>\n<p>The <a href=\"./rt_gene\">rt_gene</a> directory contains a ROS package for real-time eye gaze and blink estimation. This contains all the code required at inference time.</p>\n<p align=\"center\">\n  <video autoplay=\"\" muted=\"\" loop=\"\" poster=\"/_next/static/images/dataset_video-9614017e8d4171b6fbd32de52f27097e.webp\"><source src=\"/_next/static/images/dataset_video-9614017e8d4171b6fbd32de52f27097e.webm\" type=\"video/webm\"><source src=\"/_next/static/images/dataset_video-9614017e8d4171b6fbd32de52f27097e.mp4\" type=\"video/mp4\">RT-GENE inference example</video>\n</p>\n<h4>RT-GENE Standalone Version</h4>\n<p>The <a href=\"./rt_gene_standalone\">rt_gene_standalone</a> directory contains instructions for eye gaze estimation given a set of images. It shares code with the <code>rt_gene</code> package (above), in particular the code in <a href=\"./rt_gene/src/rt_gene\">rt_gene/src/rt_gene</a>.</p>\n<h4>RT-GENE Inpainting</h4>\n<p>The <a href=\"./rt_gene_inpainting\">rt_gene_inpainting</a> directory contains code to inpaint the region covered by the eyetracking glasses.</p>\n<p><picture><img alt=\"Inpaining example\" src=\"https:/github.com/Tobias-Fischer/rt_gene/raw/HEAD/assets/inpaint_example.jpg\"></picture></p>\n<h4>RT-GENE Model Training</h4>\n<p>The <a href=\"./rt_gene_model_training\">rt_gene_model_training</a> directory allows using the inpainted images to train a deep neural network for eye gaze estimation.</p>\n<p align=\"center\">\n  <picture><img alt=\"Accuracy on RT-GENE dataset\" src=\"https:/github.com/Tobias-Fischer/rt_gene/raw/HEAD/assets/accuracy_prl.jpg\"></picture>\n</p>\n<h2>RT-BENE (Blink Estimation)</h2>\n<h3>License + Attribution</h3>\n<p>The RT-BENE code is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">CC BY-NC-SA 4.0</a>. Commercial usage is not permitted. If you use our blink estimation code or dataset, please cite the relevant <a href=\"http://openaccess.thecvf.com/content_ICCVW_2019/html/GAZE/Cortacero_RT-BENE_A_Dataset_and_Baselines_for_Real-Time_Blink_Estimation_in_ICCVW_2019_paper.html\">paper</a>:</p>\n<pre><code>@inproceedings{CortaceroICCV2019W,\nauthor={Kevin Cortacero and Tobias Fischer and Yiannis Demiris},\nbooktitle = {Proceedings of the IEEE International Conference on Computer Vision Workshops},\ntitle = {RT-BENE: A Dataset and Baselines for Real-Time Blink Estimation in Natural Environments},\nyear = {2019},\n}\n</code></pre>\n<p>RT-BENE was supported by the EU Horizon 2020 Project PAL (643783-RIA) and a Royal Academy of Engineering Chair in Emerging Technologies to Yiannis Demiris.</p>\n<h3>Overview + Accompanying Dataset</h3>\n<p>The code is split into several parts, each having its own README. There is also an associated <a href=\"https://zenodo.org/record/3685316\">RT-BENE dataset</a>. For more information, other datasets and more open-source software please visit the Personal Robotic Lab's website: <a href=\"https://www.imperial.ac.uk/personal-robotics/software/\">https://www.imperial.ac.uk/personal-robotics/software/</a>. Please note that a lot of the code is shared with RT-GENE (see above), hence there are many references to RT-GENE below.</p>\n<p><picture><img alt=\"Paper overview\" src=\"https:/github.com/Tobias-Fischer/rt_gene/raw/HEAD/assets/rt_bene_overview.png\"></picture></p>\n<h4>RT-BENE ROS package</h4>\n<p>The <a href=\"./rt_gene\">rt_gene</a> directory contains a ROS package for real-time eye gaze and blink estimation. This contains all the code required at inference time. For blink estimation, please refer to the <a href=\"./rt_gene/scripts/estimate_blink.py\">estimate_blink.py</a> file.</p>\n<p align=\"center\">\n  <video autoplay=\"\" muted=\"\" loop=\"\" poster=\"/_next/static/images/rt_bene_inference-3d3eae7be699e19a9a12b6f72a556412.webp\"><source src=\"/_next/static/images/rt_bene_inference-3d3eae7be699e19a9a12b6f72a556412.webm\" type=\"video/webm\"><source src=\"/_next/static/images/rt_bene_inference-3d3eae7be699e19a9a12b6f72a556412.mp4\" type=\"video/mp4\">RT-BENE inference example</video>\n</p>\n<h4>RT-BENE Standalone Version</h4>\n<p>The <a href=\"./rt_bene_standalone\">rt_bene_standalone</a> directory contains instructions for blink estimation given a set of images. It makes use of the code in <a href=\"./rt_gene/src/rt_bene\">rt_gene/src/rt_bene</a>.</p>\n<h4>RT-BENE Model Training</h4>\n<p>The <a href=\"./rt_bene_model_training\">rt_bene_model_training</a> directory contains the code required to train models with the labels contained in the RT-BENE dataset (see below). We will soon at evaluation code in this directory, too.</p>\n<h4>RT-BENE Dataset</h4>\n<p><picture><img alt=\"RT-BENE labels\" src=\"https:/github.com/Tobias-Fischer/rt_gene/raw/HEAD/assets/rt_bene_labels.png\"></picture></p>\n<p>We manually annotated images contained in the \"noglasses\" part of the RT-GENE dataset. The <a href=\"https://zenodo.org/record/3685316\">RT-BENE dataset on Zenodo</a> contains the eye image patches and associated annotations to train the blink models.</p>\n","name":"RT-BENE: Real-Time Blink Estimation in Natural Environments Codebase","type":"code","url":"https://github.com/Tobias-Fischer/rt_gene","image":"repo:/assets/rt_bene_best_poster_award.png","image_fit":"contain","id":"rt_bene_code","_images":["/_next/static/images/rt_bene_best_poster_award-5ac70111852de9eac6c94cd88ef726e0.png.webp","/_next/static/images/rt_bene_best_poster_award-d72f84610eb0050287dd856b52cc99c5.png"],"src":"/content/rt-gene/rt-bene-code.md","image_position":"center"}},"__N_SSG":true}