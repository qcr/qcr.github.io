{"pageProps":{"codeData":{"content":"<p><strong>Update</strong> 2021-Jun-02: A pytorch-based (GPU/CPU) implementation of Delta Descriptors is now available with our latest work <a href=\"https://github.com/oravus/seqNet\">SeqNet</a>.</p>\n<h1>Delta Descriptors</h1>\n<p>Source code for the paper - \"Delta Descriptors: Change-Based Place Representation for Robust Visual Localization\", published in IEEE Robotics and Automation Letters (RA-L) 2020 and to be presented at IROS 2020. [<a href=\"https://arxiv.org/abs/2006.05700\">arXiv</a>] [<a href=\"https://ieeexplore.ieee.org/document/9128035\">IEEE Xplore</a>][<a href=\"https://www.youtube.com/watch?v=qY4VobAoLPY\">YouTube</a>]</p>\n<p>We propose Delta Descriptor, defined as a high-dimensional signed vector of change measured across the places observed along a route. Using a difference-based description, places can be effectively recognized despite significant appearance variations.\n<picture><img alt=\"Schematic of the proposed approach\" src=\"https:/github.com/oravus/DeltaDescriptors/raw/HEAD/ral-iros-2020-delta-descriptors-schematic.png\"></picture>\nImages on the left are from the <a href=\"https://robotcar-dataset.robots.ox.ac.uk/\">Oxford Robotcar</a> dataset.</p>\n<h2>Requirements</h2>\n<pre><code>matplotlib==2.0.2\nnumpy==1.15.2\ntqdm==4.29.1\nscipy==1.1.0\nscikit_learn==0.23.1\n</code></pre>\n<p>See <code>requirements.txt</code>, generated using <code>pipreqs==0.4.10</code> and <code>python3.5.6</code></p>\n<h2>Usage</h2>\n<h4>Download this Repository and the Nordland dataset (part)</h4>\n<p>The dataset used in our paper is available <a href=\"https://zenodo.org/record/4016653#.X1WmYM8zZCV\">here</a> (or use commands as below). Note that the download only comprises a small part (~1 GB) of the original Nordland videos released <a href=\"https://nrkbeta.no/2013/01/15/nordlandsbanen-minute-by-minute-season-by-season/\">here</a>. These videos were first used for visual place recognition in <a href=\"https://www.tu-chemnitz.de/etit/proaut/publications/openseqslam.pdf\">this</a> paper.</p>\n<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">git</span> clone https://github.com/oravus/DeltaDescriptors.git\n<span class=\"token builtin class-name\">cd</span> DeltaDescriptors/\n<span class=\"token function\">mkdir</span> data/\n<span class=\"token builtin class-name\">cd</span> data/\n<span class=\"token function\">wget</span> https://zenodo.org/record/4016653/files/nordland-part-2020.zip\n<span class=\"token function\">unzip</span> nordland-part-2020.zip\n</code></pre>\n<p>The zip contains two folders: summer and winter, where each one of them comprises 1750 images which were used for experiments conducted in our paper.</p>\n<h4>Describe and Match</h4>\n<p>Delta Descriptors are defined on top of global image descriptors, for example, NetVLAD (<a href=\"https://github.com/oravus/DeltaDescriptors/tree/master/thirdparty\">Update 05 Sep 2020: see our python wrapper</a>). Given such descriptors, compute Delta Descriptors and match across two traverses as below:</p>\n<pre class=\"language-shell\"><code class=\"language-shell\">python src/main.py --genDesc --genMatch -l <span class=\"token number\">16</span> -d delta -ip1 <span class=\"token operator\">&lt;</span>full_path_of_desc.npy<span class=\"token operator\">&gt;</span> -ip2 <span class=\"token operator\">&lt;</span>full_path_of_query_desc.npy<span class=\"token operator\">&gt;</span>\n</code></pre>\n<p>The input descriptor data is assumed to be a 2D tensor of shape <code>[numImages,numDescDims]</code>. The computed descriptors are stored in <code>.npy</code> format and the match results are stored in <code>.npz</code> format comprising a dict of two arrays: <code>matchInds</code> (matched reference index per query image) and <code>matchDists</code> (corresponding distance value). By default, output is stored in the <code>./out</code> folder but can also be specified via <code>--outPath</code> argument. To see all the options, use:</p>\n<pre class=\"language-shell\"><code class=\"language-shell\">python src/main.py --help\n</code></pre>\n<p>The options <code>--genDesc</code> and <code>--genMatch</code> can be used in isolation or together, see example usage below.</p>\n<h4>Describe only</h4>\n<p>In order to compute only the descriptors for a single traverse, use:</p>\n<pre class=\"language-shell\"><code class=\"language-shell\">python src/main.py --genDesc -l <span class=\"token number\">16</span> -d delta -ip1 <span class=\"token operator\">&lt;</span>full_path_of_desc.npy<span class=\"token operator\">&gt;</span>\n</code></pre>\n<h4>Match only</h4>\n<p>For only computing matches, given the descriptors (Delta or some other), use:</p>\n<pre class=\"language-shell\"><code class=\"language-shell\">python src/main.py --genMatch -ip1 <span class=\"token operator\">&lt;</span>full_path_of_desc.npy<span class=\"token operator\">&gt;</span> -ip2 <span class=\"token operator\">&lt;</span>full_path_of_query_desc.npy<span class=\"token operator\">&gt;</span>\n</code></pre>\n<h4>Evaluate only</h4>\n<pre class=\"language-shell\"><code class=\"language-shell\">python src/main.py --eval -mop <span class=\"token operator\">&lt;</span>full_path_of_match_output.npz<span class=\"token operator\">&gt;</span>\n</code></pre>\n<p>or evaluate directly with <code>--genMatch</code> (and possibly <code>--genDesc</code>) flag:</p>\n<pre class=\"language-shell\"><code class=\"language-shell\">python src/main.py --eval --genMatch -ip1 <span class=\"token operator\">&lt;</span>full_path_of_desc.npy<span class=\"token operator\">&gt;</span> -ip2 <span class=\"token operator\">&lt;</span>full_path_of_query_desc.npy<span class=\"token operator\">&gt;</span>\n</code></pre>\n<p>Currently, only Nordland dataset-style (1-to-1 frame correspondence) evaluation is supported, GPS/INS coordinates-based evaluation, for example, for Oxford Robotcar dataset to be added soon. Evalution code can be used to generate PR curves and the code in its current form prints Precision @ 100% Recall for localization radius of 1, 5, 10 and 20 (frames).</p>\n<h2>Citation</h2>\n<p>If you find this code or our work useful, cite it as below:</p>\n<pre><code>@article{garg2020delta,\n  title={Delta Descriptors: Change-Based Place Representation for Robust Visual Localization},\n  author={Garg, Sourav and Harwood, Ben and Anand, Gaurangi and Milford, Michael},\n  journal={IEEE Robotics and Automation Letters},\n  year={2020},\n  publisher={IEEE},\n  volume={5},\n  number={4},\n  pages={5120-5127},  \n}\n</code></pre>\n<h2>License</h2>\n<p>The code is released under MIT License.</p>\n<h2>Related Projects</h2>\n<p><a href=\"https://github.com/oravus/seqNet\">SeqNet (2021)</a>.</p>\n<p><a href=\"https://github.com/oravus/CoarseHash\">CoarseHash (2020)</a></p>\n<p><a href=\"https://github.com/oravus/seq2single\">seq2single (2019)</a></p>\n<p><a href=\"https://github.com/oravus/lostX\">LoST (2018)</a></p>\n","name":"Delta Descriptors","type":"code","url":"https://github.com/oravus/DeltaDescriptors","id":"delta_descriptors_code","image":"ral-iros-2020-delta-descriptors-schematic.png","_images":["/_next/static/images/ral-iros-2020-delta-descriptors-schematic-b5f57732c327f2f8546715b5dc3643af.png.webp","/_next/static/images/ral-iros-2020-delta-descriptors-schematic-95f5d1a50f3d92aa3344d9782ac13c32.png"],"src":"/content/visual_place_recognition/delta-descriptors.md","image_position":"center"}},"__N_SSG":true}