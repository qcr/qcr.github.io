{"pageProps":{"codeData":{"content":"<p><strong>NOTE: this software is part of the BenchBot software stack, and not intended to be run in isolation (although it can be installed independently through pip and run on results files if desired). For a working BenchBot system, please install the BenchBot software stack by following the instructions <a href=\"https://github.com/qcr/benchbot\">here</a>.</strong></p>\n<h1>BenchBot Evaluation</h1>\n<p><a href=\"http://benchbot.org\"><picture><img alt=\"BenchBot project\" src=\"https://img.shields.io/badge/collection-BenchBot-%231a2857\"></picture></a>\n<a href=\"https://qcr.github.io\"><picture><img alt=\"QUT Centre for Robotics Open Source\" src=\"https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg\"></picture></a>\n<picture><img alt=\"Primary language\" src=\"https://img.shields.io/github/languages/top/qcr/benchbot_eval\"></picture>\n<a href=\"./LICENSE.txt\"><picture><img alt=\"License\" src=\"https://img.shields.io/github/license/qcr/benchbot_eval\"></picture></a></p>\n<p>BenchBot Evaluation is a library of functions used to call evaluation methods. These methods are installed through the <a href=\"https://github.com/qcr/benchbot-addons\">BenchBot Add-ons Manager</a>, and evaluate the performance of a BenchBot system against the metric. The easiest way to use this module is through the helper scripts provided with the <a href=\"https://github.com/qcr/benchbot\">BenchBot software stack</a>.</p>\n<h2>Installing and performing evaluation with BenchBot Evaluation</h2>\n<p>BenchBot Evaluation is a Python package, installable with pip. Run the following in the root directory of where this repository was cloned:</p>\n<pre><code>u@pc:~$ pip install .\n</code></pre>\n<p>Although evaluation is best run from within the BenchBot software stack, it can be run in isolation if desired. The following code snippet shows how to perform evaluation with the <code>'omq'</code> method from Python:</p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> benchbot_eval<span class=\"token punctuation\">.</span>evaluator <span class=\"token keyword\">import</span> Evaluator<span class=\"token punctuation\">,</span> Validator\n\nValidator<span class=\"token punctuation\">(</span>results_file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>validate_results_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nEvaluator<span class=\"token punctuation\">(</span><span class=\"token string\">'omq'</span><span class=\"token punctuation\">,</span> scores_file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>This prints the final scores to the screen and saves them to a file using the following inputs:</p>\n<ul>\n<li><code>results_file</code>: points to the JSON file with the output from your experiment</li>\n<li><code>ground_truth_folder</code>: the directory containing the relevant environment ground truth JSON files</li>\n<li><code>save_file</code>: is where final scores are to be saved</li>\n</ul>\n<h2>How add-ons interact with BenchBot Evaluation</h2>\n<p>Two types of add-ons are used in the BenchBot Evaluation process: format definitions, and evaluation methods. An evaluation method's YAML file defines what results formats and ground truth formats the method supports. This means:</p>\n<ul>\n<li>this package requires installation of the <a href=\"https://github.com/qcr/benchbot_addons\">BenchBot Add-ons Manager</a> for interacting with installed add-ons</li>\n<li>the <code>results_file</code> must be a valid instance of a supported format</li>\n<li>there must be a valid ground truth available in a supported format, for the same environment as the results</li>\n<li>validity is determined by the format-specific validation function described in the format's YAML file</li>\n</ul>\n<p>Please see the <a href=\"https://github.com/qcr/benchbot_addons\">BenchBot Add-ons Manager's documentation</a> for further details on the different types of add-ons.</p>\n<h2>Creating valid results and ground truth files</h2>\n<p>The <a href=\"https://github.com/qcr/benchbot\">BenchBot software stack</a> includes tools to assist in creating results and ground truth files:</p>\n<ul>\n<li>\n<p><strong>results:</strong> are best created using the <code>empty_results()</code> and <code>results_functions()</code> helper functions in the <a href=\"https://github.com/qcr/benchbot_api\">BenchBot API</a>, which automatically populate metadata for your current task and environment.</p>\n</li>\n<li>\n<p><strong>ground truths:</strong> this package includes a <code>GroundTruthCreator</code> class to aid in creating ground truths of a specific format, for a specific environment. Example use includes:</p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> benchbot_eval<span class=\"token punctuation\">.</span>ground_truth_creator <span class=\"token keyword\">import</span> GroundTruthCreator\n\ngtc <span class=\"token operator\">=</span> GroundTruthCreator<span class=\"token punctuation\">(</span><span class=\"token string\">'object_map_ground_truth'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'miniroom:1'</span><span class=\"token punctuation\">)</span>\ngt <span class=\"token operator\">=</span> gtc<span class=\"token punctuation\">.</span>create_empty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>gtc<span class=\"token punctuation\">.</span>functions<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># ['create', 'create_object']</span>\ngt<span class=\"token punctuation\">[</span><span class=\"token string\">'ground_truth'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'objects'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> gtc<span class=\"token punctuation\">.</span>functions<span class=\"token punctuation\">(</span><span class=\"token string\">'create_object'</span><span class=\"token punctuation\">)</span>\n</code></pre>\n</li>\n</ul>\n","name":"BenchBot Evaluation Tools","type":"code","url":"https://github.com/qcr/benchbot_eval","image":"/qcr_logo_light_filled.svg","_images":["/qcr_logo_light_filled.svg"],"src":"/content/benchbot/benchbot-eval.md","id":"benchbot-eval","image_position":"center"}},"__N_SSG":true}