{"pageProps":{"codeData":{"content":"<h1>Spiking Neural Networks for Visual Place Recognition via Weighted Neuronal Assignments</h1>\n<p><a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\"><picture><img alt=\"License: MIT\" src=\"https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square\"></picture></a>\n<a href=\"https://github.com/QVPR/VPRSNN/stargazers\"><picture><img alt=\"stars\" src=\"https://img.shields.io/github/stars/QVPR/VPRSNN.svg?style=flat-square\"></picture></a>\n<picture><img alt=\"GitHub repo size\" src=\"https://img.shields.io/github/repo-size/QVPR/VPRSNN.svg?style=flat-square\"></picture>\n<a href=\"https://qcr.ai\"><picture><img alt=\"QUT Centre for Robotics\" src=\"https://img.shields.io/badge/collection-QUT%20Robotics-%23043d71?style=flat-square\"></picture></a></p>\n<p>This repository contains code for three of our papers:</p>\n<ul>\n<li>\n<p>Ensembles of Modular SNNs with/without sequence matching: <a href=\"https://arxiv.org/abs/2311.13186\">Applications of Spiking Neural Networks in Visual Place Recognition</a></p>\n</li>\n<li>\n<p>Modular SNN: <a href=\"https://arxiv.org/abs/2209.08723\">Ensembles of Compact, Region-specific &amp; Regularized Spiking Neural Networks for Scalable Place Recognition (ICRA 2023)</a> DOI: <a href=\"https://doi.org/10.1109/ICRA48891.2023.10160749\">10.1109/ICRA48891.2023.10160749</a></p>\n</li>\n<li>\n<p>Non-modular SNN: <a href=\"https://arxiv.org/abs/2109.06452\">Spiking Neural Networks for Visual Place Recognition via Weighted Neuronal Assignments (RAL + ICRA2022)</a> DOI: <a href=\"https://doi.org/10.1109/LRA.2022.3149030\">10.1109/LRA.2022.3149030</a></p>\n</li>\n</ul>\n<h2>Updates</h2>\n<p>Jan 2024:</p>\n<ul>\n<li>Updated the Nordland dataset download <a href=\"https://huggingface.co/datasets/Somayeh-h/Nordland\">link</a>.</li>\n</ul>\n<p>Dec 2023:</p>\n<ul>\n<li>Integration of ensembling and sequence matching for Modular SNN.</li>\n<li>Option to shuffle the input images.</li>\n<li>Addition of dataset configuration for Nordland, Oxford RobotCar, SFU Mountain, Synthia and St Lucia.</li>\n</ul>\n<p>Oct 2023:</p>\n<ul>\n<li>Release of learned weights of the Modular SNN on Nordland using reference traverses spring and fall.</li>\n</ul>\n<p>May 2023:</p>\n<ul>\n<li>Incorporating modularity for the SNN architecture.</li>\n<li>Improved code readability.</li>\n<li>Reduced computation for loading datasets.</li>\n</ul>\n<h2>License and Citations</h2>\n<p>This code is licensed under <a href=\"./LICENSE\">MIT License</a>.</p>\n<p>If you use our Ensemble of Modular SNNs with/without sequence matching code, please cite the following <a href=\"https://arxiv.org/abs/2311.13186\">paper</a>:</p>\n<pre><code>@article{hussaini2023applications,\n  title={Applications of Spiking Neural Networks in Visual Place Recognition},\n  author={Hussaini, Somayeh and Milford, Michael and Fischer, Tobias},\n  journal={arXiv preprint arXiv:2311.13186},\n  year={2023}\n}\n</code></pre>\n<p>If you use our Modular SNN code, please cite the following <a href=\"https://arxiv.org/abs/2209.08723\">paper</a>:</p>\n<pre><code>@inproceedings{hussaini2023ensembles,\n  title={Ensembles of compact, region-specific \\&amp; regularized spiking neural networks for scalable place recognition},\n  author={Hussaini, Somayeh and Milford, Michael and Fischer, Tobias},\n  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},\n  pages={4200--4207},\n  year={2023},\n  organization={IEEE}\n}\n</code></pre>\n<p>If you use our Non-modular SNN code, please cite the following <a href=\"https://arxiv.org/abs/2109.06452\">paper</a>:</p>\n<pre><code>@article{hussaini2022spiking,\n  title={Spiking Neural Networks for Visual Place Recognition via Weighted Neuronal Assignments},\n  author={Hussaini, Somayeh and Milford, Michael J and Fischer, Tobias},\n  journal={IEEE Robotics and Automation Letters},\n  year={2022},\n  publisher={IEEE}\n}\n</code></pre>\n<h2>Overview</h2>\n<p>Please refer to the readme files of the <a href=\"https://github.com/QVPR/VPRSNN/blob/main/ens_seq/README.md\">Ensemble of Modular SNNs &amp; sequence matching</a>, <a href=\"https://github.com/QVPR/VPRSNN/blob/main/modular_snn/README.md\">Modular SNN</a> and <a href=\"https://github.com/QVPR/VPRSNN/blob/main/non_modular_snn/README.md\">Non-modular SNN</a> folders for instructions to run the code for each work respectively.</p>\n<h2>Applications of Spiking Neural Networks in Visual Place Recognition (Ensemble of Modular SNNs with/without sequence matching)</h2>\n<p style=\"width: 50%; display: block; margin-left: auto; margin-right: auto\">\n  <picture><img alt=\"Ensemble of Modular SNNs with/without sequence matching\" src=\"https:/github.com/QVPR/VPRSNN/raw/HEAD/resources/Ens_of_modularSNNs.png\"></picture>\n</p>\n<h2>Modular SNNs for scalable place recognition (Modular SNN)</h2>\n<p>Video: https://www.youtube.com/watch?v=TNDdfmPSe1U&amp;t=137s</p>\n<p style=\"width: 50%; display: block; margin-left: auto; margin-right: auto\">\n  <picture><img alt=\"ModularSNN for scalable place recognition\" src=\"https:/github.com/QVPR/VPRSNN/raw/HEAD/resources/ICRA2023.png\"></picture>\n</p>\n<h2>SNNs for VPR (Non-modular SNN)</h2>\n<p>Video: https://www.youtube.com/watch?v=VGfv4ZVOMkw</p>\n<p style=\"width: 50%; display: block; margin-left: auto; margin-right: auto\">\n  <picture><img alt=\"VPRSNN method diagram\" src=\"https:/github.com/QVPR/VPRSNN/raw/HEAD/resources/cover_photo.png\"></picture>\n</p>\n<p>This work is an adaptation of the spiking neural network model from \"Unsupervised Learning of Digit Recognition Using Spike-Timing-Dependent Plasticity\", Diehl and Cook, (2015) for Visual Place Recognition (VPR). DOI: <a href=\"https://doi.org/10.3389/fncom.2015.00099\">10.3389/fncom.2015.00099</a>.\nVisual Place Recognition is the problem of how a robot can identify whether it has previously visited a place given an image of the place despite challenges including changes in appearance and perceptual aliasing (where two different places look similar).</p>\n<p>The code is based on the following repositories, that include the original code and the modified versions of the original code.</p>\n<p>Original code (Peter U. Diehl): https://github.com/peter-u-diehl/stdp-mnist</p>\n<p>Updated for Brian2: zxzhijia: https://github.com/zxzhijia/Brian2STDPMNIST</p>\n<p>Updated for Python3: sdpenguin: https://github.com/sdpenguin/Brian2STDPMNIST</p>\n<p>Please refer to the <a href=\"https://github.com/QVPR/VPRSNN/wiki\">wiki tab</a> for additional ablation studies.</p>\n<h2>Acknowledgements</h2>\n<p>These works were supported by the Australian Government, Intel Labs, and the Queensland University of Technology (QUT) through the Centre for Robotics.</p>\n","name":"Spiking Neural Networks for Visual Place Recognition","type":"code","url":"https://github.com/QVPR/VPRSNN","id":"vpr_snn","image":"./resources/Ens_of_modularSNNs.png","_images":["/_next/static/images/Ens_of_modularSNNs-b59ff02969917c2eb544fd14a2014936.png.webp","/_next/static/images/Ens_of_modularSNNs-2e12118a078b9b819e6e9169d4994b74.png"],"src":"/content/visual_place_recognition/vpr_snn.md","image_position":"center"}},"__N_SSG":true}